# LLMs

LLMs, what are they? how do they work? 

This repo contains my dive into llms.
The notebooks are based on some of the big trends in the 2022-2023 AI/LLM boom.

I try and cover:
1. The transformer: The base architecture of modern llms
2. Transformer Models: Introduction to some popular transformer models and a deep dive into GPT
3. Finetuning: Improve your models on your data (hopefully)
4. Inference: You've trained your model, now what.
5. Retrieval Augmented Generation (RAG): Context engineering
6. Agents: Models with side effects.

If you want to run the notebooks you should create a `models` directory and download the wanted models. 
I will be using a variety of different models (usually the lower parameter models)
