# LLMs

LLMs, what are they? how do they work? 

This repo contains my dive into llms.
The notebooks are based on some of the big trends in the 2022-2023 AI/LLM boom.

I try and cover:
1. The transformer: The base architecture of modern llms
2. The GPT architecture: The most popular llms architecture (using nanoGPT and Llama)
3. Finetuning
4. Retrieval Augmented Generation (RAG)
5. Inference

If you want to run the notebooks you should create a `models` directory and download the wanted models. 
I will be using a variety of different models (usually the lower parameter models)
